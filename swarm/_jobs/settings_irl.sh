# Defaults for Options
EBRU=${EBRU:-5000}      # experiences between reward updates
DBS=${DBS:-2}           # demonstration batch size
BBS=${BBS:-50}          # background batch size
BSS=${BSS:-500}         # background sample size
EXP=${EXP:-5000000}     # number of experiences
RNN=${RNN:-8}           # reward neural net size
POL=${POL:-Linear}      # demo policy type
RUN=${RUN:-0}           # run tag
