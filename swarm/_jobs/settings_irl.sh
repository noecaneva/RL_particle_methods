# Defaults for Options
EBRU=${EBRU:-5000}      # experiences between reward updates
DBS=${DBS:-2}           # demonstration batch size
BBS=${BBS:-50}          # background batch size
BSS=${BSS:-500}         # background sample size
EXP=${EXP:-5000000}     # number of experiences
RNN=${RNN:-8}           # reward neural net size
POL=${POL:-Linear}      # demo policy type
DIM=${DIM:-3}           # number dimensions
N=${N:-25}              # number fish
NN=${NN:-5}             # number nearest neighbours
NT=${NT:-1000}          # episode length
DAT=${DAT:-50}          # number of data
RUN=${RUN:-0}           # run tag
